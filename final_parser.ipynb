{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd /content/drive/MyDrive\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4773iRmpLEm",
        "outputId": "a53331e2-a195-417b-e789-6d5aff781206"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov3' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKRM3Tdn1oV",
        "outputId": "d9a97bc8-4a59-4523-e7b2-2e966d210f2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kbNYKdNBlY68"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import csv\n",
        "# Define the Parser class\n",
        "class Parser():\n",
        "      # Initialize the class with a PyTorch model as input\n",
        "    def __init__(self, model):\n",
        "     # Store the model as an instance variable\n",
        "        self.model = model\n",
        " # Initialize an empty list to store information about the layers\n",
        "        self.layers_info = []\n",
        "\n",
        "    def parse(self):\n",
        "        # Iterate over all the layers of the model\n",
        "        for name, module in self.model.named_modules():\n",
        "          try:\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                layer_type = \"Conv2D\"\n",
        "                input_channels = module.in_channels\n",
        "                output_channels = module.out_channels\n",
        "                kernel_size = module.kernel_size\n",
        "                stride = module.stride\n",
        "                padding = module.padding\n",
        "                layer_info = [name, layer_type, input_channels, output_channels, kernel_size, stride, padding]\n",
        "                self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.Linear):\n",
        "                layer_type = \"Linear\"\n",
        "                input_channels = module.in_features\n",
        "                output_channels = module.out_features\n",
        "                layer_info = [name, layer_type, input_channels, output_channels]\n",
        "                self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.BatchNorm2d):\n",
        "                layer_type = \"BatchNorm2D\"\n",
        "                input_channels = module.num_features\n",
        "                layer_info = [name, layer_type, input_channels]\n",
        "                self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.ReLU):\n",
        "                layer_type = \"ReLU\"\n",
        "                layer_info = [name, layer_type]\n",
        "                self.layers_info.append(layer_info)   \n",
        "            \n",
        "            elif isinstance(module, torch.nn.Sequential) and hasattr(module, \"bottleneck\"):\n",
        "                layer_type = \"Bottleneck\"\n",
        "                layer_info = [name, layer_type]\n",
        "                self.layers_info.append(layer_info) \n",
        "\n",
        "            elif isinstance(module, torch.nn.Upsample):\n",
        "              layer_type = \"Upsample\"\n",
        "              scale_factor = module.scale_factor\n",
        "              layer_info = [name, layer_type, scale_factor]\n",
        "              self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.LeakyReLU):\n",
        "              layer_type = \"LeakyReLU\"\n",
        "              negative_slope = module.negative_slope\n",
        "              layer_info = [name, layer_type, negative_slope]\n",
        "              self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.Dropout):\n",
        "               layer_type = \"Dropout\"\n",
        "               p = module.p\n",
        "               layer_info = [name, layer_type, p]\n",
        "               self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.Sequential) and hasattr(module, \"retinanet\"):\n",
        "              layer_type = \"RetinaNet\"\n",
        "              layer_info = [name, layer_type]\n",
        "              self.layers_info.append(layer_info)   \n",
        "              \n",
        "            elif isinstance(module, torch.nn.ModuleList) and hasattr(module, \"yolo\"):\n",
        "              layer_type = \"YOLO\"\n",
        "              layer_info = [name, layer_type]\n",
        "              self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.AdaptiveAvgPool2d):\n",
        "                layer_type = \"AdaptiveAvgPool2d\"\n",
        "                output_size = module.output_size\n",
        "                layer_info = [name, layer_type, output_size]\n",
        "                self.layers_info.append(layer_info)\n",
        "                \n",
        "            elif isinstance(module, torch.nn.AdaptiveMaxPool2d):\n",
        "                layer_type = \"AdaptiveMaxPool2d\"\n",
        "                output_size = module.output_size\n",
        "                layer_info = [name, layer_type, output_size]\n",
        "                self.layers_info.append(layer_info)\n",
        "                \n",
        "            elif isinstance(module, torch.nn.Tanh):\n",
        "                layer_type = \"Tanh\"\n",
        "                layer_info = [name, layer_type]\n",
        "                self.layers_info.append(layer_info)\n",
        "                \n",
        "            elif isinstance(module, torch.nn.Sigmoid):\n",
        "                layer_type = \"Sigmoid\"\n",
        "                layer_info = [name, layer_type]\n",
        "                self.layers_info.append(layer_info)\n",
        "                \n",
        "            elif isinstance(module, torch.nn.Softmax):\n",
        "                layer_type = \"Softmax\"\n",
        "                dim = module.dim\n",
        "                layer_info = [name, layer_type, dim]\n",
        "                self.layers_info.append(layer_info)\n",
        "\n",
        "            elif isinstance(module, torch.nn.MaxPool2d) or isinstance(module, torch.nn.AvgPool2d):\n",
        "                if isinstance(module, torch.nn.MaxPool2d):\n",
        "                    layer_type = \"MaxPool2D\"\n",
        "                else:\n",
        "                    layer_type = \"AvgPool2D\"\n",
        "                kernel_size = module.kernel_size\n",
        "                stride = module.stride\n",
        "                padding = module.padding\n",
        "                layer_info = [name, layer_type, kernel_size, stride, padding]\n",
        "                self.layers_info.append(layer_info)\n",
        "                \n",
        "            else:\n",
        "              layer_type = \"Other\"\n",
        "              layer_command = module\n",
        "              layer_info = [name, layer_type, input_channels, output_channels, kernel_size, stride, padding]\n",
        "              self.layers_info.append(layer_info)\n",
        "          except:\n",
        "            layer_info = [name, layer_command]\n",
        "            self.layers_info.append(layer_info)\n",
        "\n",
        "    def write_to_csv(self, file_path):\n",
        "      # Write the layer information to a CSV file\n",
        "      with open(file_path, \"w\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Name\", \"Type\", \"Input Channels\", \"Output Channels\", \"Kernel Size\", \"Stride\", \"Padding\"])\n",
        "        writer.writerows(self.layers_info)\n",
        "        for info in self.layers_info:\n",
        "          if len(info) == 4:\n",
        "            writer.writerow([info[0], info[1], info[2], info[3], \"\", \"\", \"\", \"\"])\n",
        "          elif len(info) == 3:\n",
        "            writer.writerow([info[0], info[1], info[2], \"\", \"\", \"\", \"\", \"\"])\n",
        "          elif len(info) == 7:\n",
        "            writer.writerow([info[0], info[1], info[2], info[3], info[4], info[5], info[6], \"\"])\n",
        "          elif len(info) == 8:\n",
        "            writer.writerow([info[0], info[1], info[2], info[3], info[4], info[5], info[6], info[7]])\n",
        "          else:\n",
        "            writer.writerow([info[0], info[1], \"\", \"\", \"\", \"\", \"\", \"\"])\n",
        "\n",
        "    \n",
        "\n",
        "           \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "# Instantiate the ModelParser class and pass in the model\n",
        "parser = Parser(resnet50)\n",
        "\n",
        "# Call the parse_model method to parse the model\n",
        "parser.parse()\n",
        "\n",
        "# Call the write_to_csv method to write the parsed information to a CSV file\n",
        "parser.write_to_csv('resnet50_final_2_parsed.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whefXGK6llSK",
        "outputId": "a0ac7a32-205c-42ea-dde8-6f66bf31e461"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "# Load the pre-trained SSD-Large model\n",
        "ssd_large = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp16')\n",
        "# Instantiate the ModelParser class and pass in the model\n",
        "parser = Parser(ssd_large)\n",
        "\n",
        "# Call the parse_model method to parse the model\n",
        "parser.parse()\n",
        "\n",
        "# Call the write_to_csv method to write the parsed information to a CSV file\n",
        "parser.write_to_csv('ssd_final_2_large.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vKqOtKxmiZf",
        "outputId": "94970a66-6113-4393-861e-8311cc3d1e33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "import pandas as pd\n",
        "\n",
        "# Load the pre-trained BERT-768 model\n",
        "Bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "# Instantiate the ModelParser class and pass in the model\n",
        "parser = Parser(Bert)\n",
        "\n",
        "# Call the parse_model method to parse the model\n",
        "parser.parse()\n",
        "\n",
        "# Call the write_to_csv method to write the parsed information to a CSV file\n",
        "parser.write_to_csv('Bert_final_2.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z73j-DK2m5jB",
        "outputId": "ddab8153-66bf-40e8-e91f-ce682975f878"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "# Load RetinaNet model\n",
        "retinanet = torchvision.models.detection.retinanet.retinanet_resnet50_fpn(pretrained=True)\n",
        "\n",
        "parser = Parser(retinanet)\n",
        "\n",
        "# Call the parse_model method to parse the model\n",
        "parser.parse()\n",
        "\n",
        "# Call the write_to_csv method to write the parsed information to a CSV file\n",
        "parser.write_to_csv('retinanet_final_2.csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VkWVG3goBVk",
        "outputId": "982cc62d-68a9-4098-b0bb-7e08d03e3231"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "yolo = torch.hub.load('ultralytics/yolov3', 'yolov3')  # or yolov3-spp, yolov3-tiny, custom\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6cqpVArI9c",
        "outputId": "6ca2afda-4b18-4450-ee78-b7421b48dbe2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov3_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = Parser(yolo)\n",
        "\n",
        "# Call the parse_model method to parse the model\n",
        "parser.parse()\n",
        "\n",
        "# Call the write_to_csv method to write the parsed information to a CSV file\n",
        "parser.write_to_csv('yolo_final_2.csv')\n"
      ],
      "metadata": {
        "id": "JQsBISJtrQEu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FESFEeNp-Ruv"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}